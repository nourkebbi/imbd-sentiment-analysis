{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPaWLFOkfTxYh1bX4bvz9hv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nourkebbi/imbd-sentiment-analysis/blob/main/IMBD_sentiment_analysis_data_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing all libraries"
      ],
      "metadata": {
        "id": "loNUERZ8jRNP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "U5u9495IjDPD"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# For text preprocessing\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "# For model building\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ai975PY1jQZK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing dataset"
      ],
      "metadata": {
        "id": "n9YanxA6jUJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGSima7EjWsT",
        "outputId": "09574e26-5e2c-4662-d206-3d5db1eab886"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25.7M/25.7M [00:00<00:00, 156MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews/versions/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read the csv file"
      ],
      "metadata": {
        "id": "3fSRZ0oVnX9O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(f\"{path}/IMDB Dataset.csv\")"
      ],
      "metadata": {
        "id": "x7CBmQ84nZy1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Break review column into tokens and clean the review column"
      ],
      "metadata": {
        "id": "GFESknwLoRqB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stemmer = PorterStemmer()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VhexELsoVxI",
        "outputId": "9d4acdad-0f8a-4b93-bd69-2d4d36f7d7fc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.review[3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "N_sGIITIrZEM",
        "outputId": "7d9fd54a-f6c4-402a-b08c-1ffcf8353a70"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.<br /><br />OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. As for the shots with Jake: just ignore them.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHfKe14Brrd_",
        "outputId": "66785f80-6c2b-42ee-b33d-8507d574e4d2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string,time\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "ps = PorterStemmer()\n",
        "exclude = string.punctuation\n",
        "def remove_url(text):\n",
        "    pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "    return pattern.sub(r'', text)\n",
        "def remove_punc(text):\n",
        "    for char in exclude:\n",
        "        text = text.replace(char,'')\n",
        "    return text\n",
        "def stem_words(text):\n",
        "    return \" \".join([ps.stem(word) for word in text.split()])"
      ],
      "metadata": {
        "id": "uLNvUUPK74MV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = 'I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs.'\n",
        "\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = remove_url(text)\n",
        "    text = remove_punc(text)\n",
        "    text = stem_words(text)\n",
        "    text = nltk.word_tokenize(text)\n",
        "    text = ' '.join(text)\n",
        "    return text\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-u714F4U5tTd"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['review'] = df['review'].apply(preprocess_text)"
      ],
      "metadata": {
        "id": "Jmtw63fr5q1v"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing"
      ],
      "metadata": {
        "id": "dlLAtU3FxHPa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.review[3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "WkhOg6AaxJ_C",
        "outputId": "e6a7565d-4822-4676-d2cf-6e9bcf0e756c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'basic there a famili where a littl boy jake think there a zombi in hi closet hi parent are fight all the timebr br thi movi is slower than a soap opera and suddenli jake decid to becom rambo and kill the zombiebr br ok first of all when your go to make a film you must decid if it a thriller or a drama as a drama the movi is watchabl parent are divorc argu like in real life and then we have jake with hi closet which total ruin all the film i expect to see a boogeyman similar movi and instead i watch a drama with some meaningless thriller spotsbr br 3 out of 10 just for the well play parent descent dialog as for the shot with jake just ignor them'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenizing the data"
      ],
      "metadata": {
        "id": "garHcMSZ_ER5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=10000) #tokenizing number of words top 10000 into pieces\n",
        "tokenizer.fit_on_texts(df['review'].values) #removing duplicates of tokens in review text\n",
        "X = tokenizer.texts_to_sequences(df['review'].values) #assigning an Integer to each token"
      ],
      "metadata": {
        "id": "v7UItWlA_Fv5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pad sequences"
      ],
      "metadata": {
        "id": "ADCuHrMgbNOs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = pad_sequences(X, maxlen=100) #making all sequences are of the same length - here its 100"
      ],
      "metadata": {
        "id": "enLHCxyQbPEs"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting positive/negative to int"
      ],
      "metadata": {
        "id": "QYhZbT_Ebaeq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = df['sentiment'].replace({'positive': 1, 'negative': 0})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPA6iWuvbcsg",
        "outputId": "ded7cabe-2258-4356-acc6-f5de730f6ab4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-beb1921602e5>:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  y = df['sentiment'].replace({'positive': 1, 'negative': 0})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create and compile model"
      ],
      "metadata": {
        "id": "077Vu6pubhak"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define model architecture"
      ],
      "metadata": {
        "id": "pc-1b4BQbjTO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([  #model used for sentimental analysis and text classification\n",
        "    Embedding(10000, 64), #classifies each word to 64 vectors\n",
        "    LSTM(64), #long-short-term-memory understands the context behind the words\n",
        "    Dense(1, activation='sigmoid') #classifies each word between 0 and 1 (negative or positive)\n",
        "])"
      ],
      "metadata": {
        "id": "BJysfF9Kbme0"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compiling the model"
      ],
      "metadata": {
        "id": "wl9O3KTFcWpO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "#compiles the models - loss is how much wrong the sentiment is - measures the difference between the output and the correct sentiment\n",
        "#optimizer adam is the things that improves the quality of the output\n",
        "#metrics: how much the data is correct with respect to the data from IMBD pos/neg"
      ],
      "metadata": {
        "id": "O-wKOE6IcZq1"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model"
      ],
      "metadata": {
        "id": "28O6WAuicdTh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split data"
      ],
      "metadata": {
        "id": "2OD45NE8chAx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "# x is the input, y is the output values\n",
        "#20% of the data is used for validation and 80% for training\n",
        "#random state - random num generator to ensure the split happens in the same way everytime"
      ],
      "metadata": {
        "id": "nZBa72pOcjD2"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model"
      ],
      "metadata": {
        "id": "OnwTiXQrcrMr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))\n",
        "# x_train is input to be trained\n",
        "# y_train is output to be learnt from\n",
        "# epochs is 10 - number of times the model is trained\n",
        "# batch size is the number of samples trained each time\n",
        "# validation data is a function that monitors the model performance\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J04w6kBOctn1",
        "outputId": "ccf1823e-4d2c-46b8-e779-6fa98d171a9d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 55ms/step - accuracy: 0.9913 - loss: 0.0305 - val_accuracy: 0.8434 - val_loss: 0.6281\n",
            "Epoch 2/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 54ms/step - accuracy: 0.9934 - loss: 0.0239 - val_accuracy: 0.8513 - val_loss: 0.6927\n",
            "Epoch 3/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 54ms/step - accuracy: 0.9942 - loss: 0.0220 - val_accuracy: 0.8524 - val_loss: 0.7550\n",
            "Epoch 4/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 57ms/step - accuracy: 0.9962 - loss: 0.0149 - val_accuracy: 0.8534 - val_loss: 0.8322\n",
            "Epoch 5/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 55ms/step - accuracy: 0.9946 - loss: 0.0187 - val_accuracy: 0.8527 - val_loss: 0.8055\n",
            "Epoch 6/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 54ms/step - accuracy: 0.9956 - loss: 0.0144 - val_accuracy: 0.8486 - val_loss: 0.7789\n",
            "Epoch 7/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 54ms/step - accuracy: 0.9973 - loss: 0.0096 - val_accuracy: 0.8503 - val_loss: 0.8110\n",
            "Epoch 8/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 54ms/step - accuracy: 0.9982 - loss: 0.0068 - val_accuracy: 0.8479 - val_loss: 0.8947\n",
            "Epoch 9/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 54ms/step - accuracy: 0.9972 - loss: 0.0095 - val_accuracy: 0.8448 - val_loss: 0.8717\n",
            "Epoch 10/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 54ms/step - accuracy: 0.9970 - loss: 0.0101 - val_accuracy: 0.8382 - val_loss: 0.8893\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78cfc42ac040>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate data on Validation set"
      ],
      "metadata": {
        "id": "QLvC1ENRc5m9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_val, y_val)\n",
        "print('Test Loss:', loss)\n",
        "print('Test Accuracy:', accuracy)\n",
        "#using the trained data to evaluate the loss and the accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JspdW8J0c9wG",
        "outputId": "7b197121-933f-449c-b7b2-269255af12be"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.8378 - loss: 0.8957\n",
            "Test Loss: 0.8892940282821655\n",
            "Test Accuracy: 0.8381999731063843\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making predictions"
      ],
      "metadata": {
        "id": "sa2jUBo7iOJF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_review = \"This movie is omg!\""
      ],
      "metadata": {
        "id": "XFQZ8GP5iP60"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenize and pad new text"
      ],
      "metadata": {
        "id": "ihSShA5TiTq7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_seq = tokenizer.texts_to_sequences([new_review])\n",
        "new_padded_seq = pad_sequences(new_seq, maxlen=100)"
      ],
      "metadata": {
        "id": "1zO6NkAniVxm"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make prediction"
      ],
      "metadata": {
        "id": "hxqRj--YiXnC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model.predict(new_padded_seq)\n",
        "print(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lmmIjB1ib4c",
        "outputId": "61961518-053c-4df3-846f-59162f908a8a"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "[[1.1786375e-05]]\n"
          ]
        }
      ]
    }
  ]
}